<html>

<head>
    <H1> Faust dynamically generated polyphonic MIDI ready WebAudio node </H1>
</head>

<body>

    <P> Organ volume:
        <input type="range" oninput="changeVolume(event) " min="0" max="1" value="0.5" step="0.01" />

        <!-- Load 'libfaust' library and wrapper code -->
        <script src="libfaust-wasm.js"></script>
        <!-- Load the Faust JS library -->
        <script src="FaustLibrary.js"></script>

        <script>

            function workletAvailable() {
                if (typeof (OfflineAudioContext) === "undefined") return false;
                var context = new OfflineAudioContext(1, 1, 44100);
                return context.audioWorklet && typeof context.audioWorklet.addModule === 'function';
            }

            if (typeof (WebAssembly) === "undefined" || !workletAvailable()) {
                alert("WebAssembly or AudioWorklet is not supported in this browser !")
            }

            // Init audio context
            var isWebKitAudio = (typeof (webkitAudioContext) !== "undefined");
            var audio_context = (isWebKitAudio) ? new webkitAudioContext({ latencyHint: 0.00001 }) : new AudioContext({ latencyHint: 0.00001 });
            audio_context.destination.channelInterpretation = "discrete";

            var organ_dsp = null;
            var midi_input = [];
            var dsp_code_url = "http://127.0.0.1:8000/organ.dsp";

            // Slider handler to change the 'noise' volume
            function changeVolume(event) {
                if (organ_dsp) {
                    var val = event.target.value;
                    val = parseFloat(val);
                    console.log(val);
                    organ_dsp.setParamValue("/FaustDSP/volume", val);
                }
            }

            // MIDI input handling
            function keyOn(channel, pitch, velocity) {
                if (organ_dsp) {
                    organ_dsp.keyOn(channel, pitch, velocity);
                }
            }

            function keyOff(channel, pitch, velocity) {
                if (organ_dsp) {
                    organ_dsp.keyOff(channel, pitch, velocity);
                }
            }

            function pitchWheel(channel, bend) {
                if (organ_dsp) {
                    organ_dsp.pitchWheel(channel, bend);
                }
            }

            function ctrlChange(channel, ctrl, value) {
                if (organ_dsp) {
                    organ_dsp.ctrlChange(channel, ctrl, value);
                }
            }

            // Generic MIDI handler
            function midiMessageReceived(ev) {
                var cmd = ev.data[0] >> 4;
                var channel = ev.data[0] & 0xf;
                var data1 = ev.data[1];
                var data2 = ev.data[2];

                if (channel === 9) {
                    return;
                } else if (cmd === 8 || ((cmd === 9) && (data2 === 0))) {
                    keyOff(channel, data1, data2);
                } else if (cmd === 9) {
                    keyOn(channel, data1, data2);
                } else if (cmd === 11) {
                    ctrlChange(channel, data1, data2);
                } else if (cmd === 14) {
                    pitchWheel(channel, (data2 * 128.0 + data1));
                }
            }

            function onerrorcallback(error) {
                console.log(error);
            }

            function onsuccesscallbackStandard(access) {
                access.onstatechange = function (e) {
                    if (e.port.type === "input") {
                        if (e.port.state === "connected") {
                            console.log(e.port.name + " is connected");
                            e.port.onmidimessage = midiMessageReceived;
                        } else if (e.port.state === "disconnected") {
                            console.log(e.port.name + " is disconnected");
                            e.port.onmidimessage = null;
                        }
                    }
                }

                for (var input of access.inputs.values()) {
                    input.onmidimessage = midiMessageReceived;
                    console.log(input.name + " is connected");
                }
            }

            function activateMIDIInput() {
                console.log("activateMIDIInput");
                if (typeof (navigator.requestMIDIAccess) !== "undefined") {
                    navigator.requestMIDIAccess().then(onsuccesscallbackStandard, onerrorcallback);
                } else {
                    alert("MIDI input cannot be activated, either your browser still does't have it, or you need to explicitly activate it.");
                }
            }

            // Load handler which call 'startorgan_dsp' when 'libfaust-wasm.js' is properly loaded
            FaustModule().then((module) => { startorgan(module); });

            async function startorgan(module) {

                // Load the DSP file
                var dsp_file = await fetch(dsp_code_url);
                var dsp_code = await dsp_file.text();

                // Dynamically create the Faust generated node from explicit DSP source in 'dsp_code'
                organ_dsp = await Faust.compileAudioNode(audio_context, module, dsp_code, null, 16);

                // Print DSP JSON	
                console.log(organ_dsp.getJSON());
                // Print paths to be used with 'setParamValue'
                console.log(organ_dsp.getParams());
                // Connect it to output as a regular WebAudio node
                organ_dsp.connect(audio_context.destination);
                // Activate MIDI
                activateMIDIInput();
            }

            // To activate audio on iOS
            window.addEventListener('touchstart', function () {
                if (audio_context.state !== "suspended") return;
                // create empty buffer
                var buffer = audio_context.createBuffer(1, 1, 22050);
                var source = audio_context.createBufferSource();
                source.buffer = buffer;

                // connect to output (your speakers)
                source.connect(audio_context.destination);

                // play the file
                source.start();

                audio_context.resume().then(() => console.log("Audio resumed"));
            }, false);

            // On desktop
            window.addEventListener("mousedown", () => {
                if (audio_context.state !== "suspended") return;
                audio_context.resume().then(() => console.log("Audio resumed"))
            });

        </script>

</body>

</html>